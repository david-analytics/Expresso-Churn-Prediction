{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>REGION</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>MONTANT</th>\n",
       "      <th>FREQUENCE_RECH</th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>ARPU_SEGMENT</th>\n",
       "      <th>FREQUENCE</th>\n",
       "      <th>DATA_VOLUME</th>\n",
       "      <th>ON_NET</th>\n",
       "      <th>ORANGE</th>\n",
       "      <th>TIGO</th>\n",
       "      <th>ZONE1</th>\n",
       "      <th>ZONE2</th>\n",
       "      <th>MRG</th>\n",
       "      <th>REGULARITY</th>\n",
       "      <th>TOP_PACK</th>\n",
       "      <th>FREQ_TOP_PACK</th>\n",
       "      <th>CHURN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dcf68cc2fb515ccad7d8b9b3bd80ee2a4b270063</td>\n",
       "      <td>SAINT-LOUIS</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>62</td>\n",
       "      <td>All-net 500F=2000F;5d</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71c44b5ba328db5c4192a80f7cf8f244d9350ed0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4427.0</td>\n",
       "      <td>1476.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>40</td>\n",
       "      <td>Data: 100 F=40MB,24H</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce46411b1526c94f20a383b8cb188f8d27f82a0a</td>\n",
       "      <td>TAMBACOUNDA</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>32</td>\n",
       "      <td>All-net 500F=2000F;5d</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id       REGION        TENURE  \\\n",
       "0  dcf68cc2fb515ccad7d8b9b3bd80ee2a4b270063  SAINT-LOUIS  K > 24 month   \n",
       "1  71c44b5ba328db5c4192a80f7cf8f244d9350ed0          NaN  K > 24 month   \n",
       "2  ce46411b1526c94f20a383b8cb188f8d27f82a0a  TAMBACOUNDA  K > 24 month   \n",
       "\n",
       "   MONTANT  FREQUENCE_RECH  REVENUE  ARPU_SEGMENT  FREQUENCE  DATA_VOLUME  \\\n",
       "0  17000.0            32.0  18000.0        6000.0       34.0          NaN   \n",
       "1   4300.0            29.0   4427.0        1476.0       37.0       1764.0   \n",
       "2   1500.0             3.0   1500.0         500.0        3.0          NaN   \n",
       "\n",
       "   ON_NET  ORANGE  TIGO  ZONE1  ZONE2 MRG  REGULARITY               TOP_PACK  \\\n",
       "0    97.0   355.0   6.0    NaN    NaN  NO          62  All-net 500F=2000F;5d   \n",
       "1     8.0     3.0   0.0    NaN    2.0  NO          40   Data: 100 F=40MB,24H   \n",
       "2    30.0    30.0   NaN    NaN    NaN  NO          32  All-net 500F=2000F;5d   \n",
       "\n",
       "   FREQ_TOP_PACK  CHURN  \n",
       "0           35.0      0  \n",
       "1           22.0      0  \n",
       "2            3.0      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'REGION', 'TENURE', 'MONTANT', 'FREQUENCE_RECH', 'REVENUE',\n",
       "       'ARPU_SEGMENT', 'FREQUENCE', 'DATA_VOLUME', 'ON_NET', 'ORANGE', 'TIGO',\n",
       "       'ZONE1', 'ZONE2', 'MRG', 'REGULARITY', 'TOP_PACK', 'FREQ_TOP_PACK',\n",
       "       'CHURN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['MRG'] = train['MRG'].factorize()[0]\n",
    "train['TENURE'] = train['TENURE'].factorize()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['MRG'] = test['MRG'].factorize()[0]\n",
    "test['TENURE'] = test['TENURE'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('TOP_PACK', axis=1)\n",
    "test = test.drop('TOP_PACK', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.000000 columns were dropped\n"
     ]
    }
   ],
   "source": [
    "to_drop = [columns for columns in train.columns[train.isnull().mean()>=0.7]]\n",
    "to_drop.extend([columns for columns in train.columns if columns not in ['user_id', 'REGION']\n",
    "                if train[columns].std() == 0])\n",
    "to_drop.append('user_id')\n",
    "train.drop(to_drop, axis=1, inplace=True)\n",
    "test.drop(to_drop, axis=1, inplace=True)\n",
    "print(\"%f columns were dropped\"%(len(to_drop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(-999)\n",
    "test = test.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGION</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>MONTANT</th>\n",
       "      <th>FREQUENCE_RECH</th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>ARPU_SEGMENT</th>\n",
       "      <th>FREQUENCE</th>\n",
       "      <th>DATA_VOLUME</th>\n",
       "      <th>ON_NET</th>\n",
       "      <th>ORANGE</th>\n",
       "      <th>TIGO</th>\n",
       "      <th>REGULARITY</th>\n",
       "      <th>FREQ_TOP_PACK</th>\n",
       "      <th>CHURN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAINT-LOUIS</td>\n",
       "      <td>0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>62</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-999</td>\n",
       "      <td>0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4427.0</td>\n",
       "      <td>1476.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        REGION  TENURE  MONTANT  FREQUENCE_RECH  REVENUE  ARPU_SEGMENT  \\\n",
       "0  SAINT-LOUIS       0  17000.0            32.0  18000.0        6000.0   \n",
       "1         -999       0   4300.0            29.0   4427.0        1476.0   \n",
       "\n",
       "   FREQUENCE  DATA_VOLUME  ON_NET  ORANGE  TIGO  REGULARITY  FREQ_TOP_PACK  \\\n",
       "0       34.0       -999.0    97.0   355.0   6.0          62           35.0   \n",
       "1       37.0       1764.0     8.0     3.0   0.0          40           22.0   \n",
       "\n",
       "   CHURN  \n",
       "0      0  \n",
       "1      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-999           157520\n",
      "DAKAR           95517\n",
      "THIES           33374\n",
      "SAINT-LOUIS     22125\n",
      "LOUGA           18513\n",
      "KAOLACK         18042\n",
      "DIOURBEL        12576\n",
      "TAMBACOUNDA     10273\n",
      "KAFFRINE         8181\n",
      "KOLDA            7204\n",
      "FATICK           6638\n",
      "MATAM            5255\n",
      "ZIGUINCHOR       4012\n",
      "SEDHIOU           589\n",
      "KEDOUGOU          181\n",
      "Name: REGION, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['REGION'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'REGION': {-999: 1, 'DAKAR': 2, 'DIOURBEL': 3, 'FATICK': 4, 'KAFFRINE': 5, 'KAOLACK': 6, 'KEDOUGOU': 7, 'KOLDA': 8, 'LOUGA': 9, 'MATAM': 10, 'SAINT-LOUIS': 11, 'SEDHIOU': 12, 'TAMBACOUNDA': 13, 'THIES': 14, 'ZIGUINCHOR': 15}}\n"
     ]
    }
   ],
   "source": [
    "label = train['REGION'].astype('category').cat.categories.tolist()\n",
    "replace = {'REGION' : {k: v for k,v in zip(label,list(range(1,len(label)+1)))}}\n",
    "print(replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.replace(replace, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'REGION': {-999: 1, 'DAKAR': 2, 'DIOURBEL': 3, 'FATICK': 4, 'KAFFRINE': 5, 'KAOLACK': 6, 'KEDOUGOU': 7, 'KOLDA': 8, 'LOUGA': 9, 'MATAM': 10, 'SAINT-LOUIS': 11, 'SEDHIOU': 12, 'TAMBACOUNDA': 13, 'THIES': 14, 'ZIGUINCHOR': 15}}\n"
     ]
    }
   ],
   "source": [
    "label = test['REGION'].astype('category').cat.categories.tolist()\n",
    "replace = {'REGION' : {k: v for k,v in zip(label,list(range(1,len(label)+1)))}}\n",
    "print(replace)\n",
    "test.replace(replace, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train['FREQUENCY_DIFFERENCE'] = train['FREQUENCE_RECH'] - train['FREQUENCE']\n",
    "#train['FREQUENCY_PER_DATA_VOLUME'] = train['DATA_VOLUME'] / train['FREQUENCE']\n",
    "test['FREQUENCY_DIFFERENCE'] = test['FREQUENCE_RECH'] - test['FREQUENCE']\n",
    "#test['FREQUENCY_PER_DATA_VOLUME'] = test['DATA_VOLUME'] / test['FREQUENCE']\n",
    "#train['REGULARITY_PER_REVENUE'] = train['REVENUE'] / train['REGULARITY']\n",
    "#test['REGULARITY_PER_REVENUE'] = test['REVENUE'] / test['REGULARITY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "train_trans = sc.fit_transform(train.drop(['CHURN'], axis = 1))\n",
    "test_trans = sc.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= train['CHURN']\n",
    "X = train_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320000, 13)\n",
      "(80000, 13)\n",
      "(320000,)\n",
      "(80000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(true, pred):\n",
    "    from sklearn.metrics import log_loss\n",
    "    return np.sqrt(log_loss(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbr =GradientBoostingClassifier(n_estimators=900, learning_rate=0.07, max_depth=11)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred = gbr.predict_proba(X_test)\n",
    "loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat = CatBoostClassifier(iterations=450,random_strength=11,depth=8,learning_rate=0.05)\n",
    "cat.fit(X_train, y_train)\n",
    "y_pred = cat.predict_proba(X_test)\n",
    "loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5819468\ttotal: 662ms\tremaining: 5m 30s\n",
      "499:\tlearn: 0.2471125\ttotal: 1m 39s\tremaining: 0us\n",
      "0.25154625822460747\n",
      "0:\tlearn: 0.5883751\ttotal: 194ms\tremaining: 1m 36s\n",
      "499:\tlearn: 0.2467036\ttotal: 1m 35s\tremaining: 0us\n",
      "0.25316249693277365\n",
      "0:\tlearn: 0.5888112\ttotal: 220ms\tremaining: 1m 49s\n",
      "499:\tlearn: 0.2465459\ttotal: 1m 41s\tremaining: 0us\n",
      "0.25389201751353646\n",
      "0:\tlearn: 0.5819622\ttotal: 186ms\tremaining: 1m 32s\n",
      "499:\tlearn: 0.2477039\ttotal: 1m 41s\tremaining: 0us\n",
      "0.2507624880085633\n",
      "Average:  0.2523408151698702\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "kfold, scores = KFold(n_splits=4, shuffle=True, random_state=221), list()\n",
    "pred_tot_cb = []\n",
    "for train, test in kfold.split(X):\n",
    "    x_train, x_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    model = CatBoostClassifier(random_state=42,  n_estimators=500, verbose=1000,learning_rate=0.07,\n",
    "                               eval_metric='Logloss', early_stopping_rounds=250)\n",
    "    model.fit(x_train, y_train)\n",
    "    preds = model.predict_proba(x_test)\n",
    "    score = log_loss(y_test, preds)\n",
    "    scores.append(score)\n",
    "    test_pred = model.predict(test_trans)\n",
    "    pred_tot_cb.append(test_pred)\n",
    "    print(score)\n",
    "print(\"Average: \", sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 0, ..., 0, 0, 0], dtype=int64),\n",
       " array([1, 1, 0, ..., 0, 0, 0], dtype=int64),\n",
       " array([1, 1, 0, ..., 0, 0, 0], dtype=int64),\n",
       " array([1, 1, 0, ..., 0, 0, 0], dtype=int64)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tot_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators=[500,800,1500,]\n",
    "max_features=['auto', 'sqrt', 'log2']\n",
    "max_depth=[15,30,50]\n",
    "max_depth.append(None)\n",
    "min_samples_split=[5,15,20]\n",
    "min_samples_leaf=[5,10,15]\n",
    "\n",
    "grid_param = {'n_estimators': n_estimators,\n",
    "             'max_features': max_features,\n",
    "             'max_depth': max_depth,\n",
    "             'min_samples_split': min_samples_split,\n",
    "             'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "rfr=RandomForestClassifier(random_state=1)\n",
    "rfr_random=RandomizedSearchCV(estimator = rfr,\n",
    "                             param_distributions = grid_param, n_iter = 2,\n",
    "                             cv = 4, verbose=2, random_state=42,\n",
    "                             n_jobs = -1)\n",
    "rfr_random.fit(X_train, y_train)\n",
    "print(rfr_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500, min_samples_split=15, min_samples_leaf=15, max_features='auto', max_depth=30)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict_proba(X_test)\n",
    "loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat = CatBoostClassifier(iterations=1000,random_strength=9,depth=7,learning_rate=0.05)\n",
    "#random_strength': 9, 'learning_rate': 0.05, 'iterations': 900, 'depth': 7\n",
    "cat.fit(X_train, y_train)\n",
    "y_pred = cat.predict_proba(X_test)\n",
    "loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_proba(test_trans)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78326352]\n"
     ]
    }
   ],
   "source": [
    "print(prediction[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>CHURN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>af900d87e73b7ff6509d2203df4704a98aa5f2a6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5335efd940280b82143272275637d1e65d37eadb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a581f4fa08677c26f83f643248c667e241043086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64f67177d0775262b8087a9e2e3b8061b6324ae6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0d6009a4594c4be22449b8d9cc01a0bcea98faea</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id  CHURN\n",
       "0  af900d87e73b7ff6509d2203df4704a98aa5f2a6      0\n",
       "1  5335efd940280b82143272275637d1e65d37eadb      0\n",
       "2  a581f4fa08677c26f83f643248c667e241043086      0\n",
       "3  64f67177d0775262b8087a9e2e3b8061b6324ae6      0\n",
       "4  0d6009a4594c4be22449b8d9cc01a0bcea98faea      0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('sample_submission.csv')\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donee\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame({'user_id':submit.user_id,'CHURN':prediction}).to_csv('Acesubmission.csv', index=False)\n",
    "print('Donee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
